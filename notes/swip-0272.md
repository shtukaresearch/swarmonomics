---
title: Stake registry update queue
author: Andrew Macpherson (@awmacpherson)
discussions-to: https://discord.gg/Q6BvSkCv (Swarm Discord)
status: WIP
category: Core
created: 2025-10-10
---

# Stake registry update queue

## Abstract

Currently, the following operations are possible on a stake balance:

* Create/destroy
* Deposit/withdraw
* Update height (up/down)
* Update overlay address

Some of these operations — for example, height reduction — result in a node's exit from or reduced financial commitment to a neighbourhood, negatively affecting the storage service. For the sake of service stability, we propose a method to throttle such operations by means of an *update queue* which imposes delays on service-reducing changes.

Requests to update registered information (stake balance, height, and overlay address) or withdraw excess stake are placed on a FIFO queue, maintained by a new UpdateQueue contract, and executed lazily on calls to `commit()` in the Redistribution contract. Pending updates may also be executed voluntarily by calling the UpdateQueue contract directly — we expect that users will wish to do this in the case of withdrawals. An update is not processed unless a certain number of complete rounds has elapsed since it was placed on the queue. The number of rounds depends on the nature of the update; updates that allow stake balances to be reduced or nodes to remove neighbourhoods from their area of responsibility are subjected to longer delays.

## Rationale

* *One queue.* All types of updates for all stake owners are considered to be part of one queue. While some queue designs may allow for handling different owners or different update types in isolation, others — such as a global churn rate limiter — require tracking global state. To future proof the queue interface against possible changes to queue design, other components of the system must treat the entire network-wide queue as a single black box.

* *2 round thaw.* The 2 round thaw currently implemented (but not really documented) in the `commit()` method of the Redistribution contract is absorbed into this queue. The delay length is preserved as the `BASE_UPDATE_DELAY` parameter.

* *Event emission.* Requesting updates should emit an event, because NOs will want to track these for their strategies. We don't need to emit an event when the update is actually applied, as this generally doesn't happen until the next round that node is elected.

* *Stake balance changes.* In the case of changes to stake balance, a transfer must be triggered as well as changes to the stake contract. If the change requested is a deposit, funds must be deposited at the time of the request. In the case of a withdrawal, funds are withdrawn when the update is executed.

* *Per-neighbourhood delay scaling.* It may make sense to adjust the delay of changes depending on the before and after population of each neighbourhood affected by the change. The core example is to reduce delay for nodes leaving a neighbourhood with large population (and in the case of overlay change, entering one with small population). This would require the queue system to be able to estimate replication depth and enlarges the design space considerably.

* *Maximum queue length.* Although unlikely to be an issue in practice, in principle an update queue could grow so long that it cannot be emptied in a single block. Therefore, there shold be a maximum number of updates that can be held in the queue for each owner. It probably won't cause a big problem if the number is quite small, e.g. 10.

  An alternative approach would be to internally merge operations using an internal representation closed under composition. While we can imagine ways to do this for the set of operations the queue is currently expected to process, it would complicate the process of adding any new types of operation to the queue or changing the queue algorithm. A simple maximum queue length is easy to implement, universal, and unlikely to raise any serious objections.

### Effect of pending status on other components

* *Price oracle.* For the purposes of adjusting storage prices, the reveal counter should discount nodes currently waiting to exit the neighbourhood. Fully discounting it allows another node to enter and sync before the population shrinks without triggering negative price pressure. If no new node is ready to enter, this allows the system to begin adjusting prices from as soon as the potential supply shrinkage is known.

  It is natural to ask whether a node waiting to *enter* a different neighbourhood, for example by an overlay change, be considered as part of that neighbourhood for the sake of price adjustments. The current design means that we can only do this if nodes participate in the new neighbourhood while waiting in the queue, which would mean they need to be treated as having two overlay addresses for a period. Since reacting to neighbourhood underpopulation is more important than reacting to overpopulation, it may be OK to skip this one.

  This discounting could also be on a time-based curve, but that seems like it might be hard to implement.

* *Reward sharing.* For most of the benefits of an exit queue to work, nodes must be incentivised to continue operating while they are in the queue. Hence, they must be able to continue participating in reward sharing (and penalties) as normal while waiting. Accordingly, they must participate in all the activities that qualify them for reward sharing, i.e. reserve consensus and storage and density proofs.

* *Freezing.* If a node gets frozen while waiting to withdraw funds, what happens?

  * If withdrawal is allowed even if the stake is frozen at the end of the wait period, the penalty implied by freezing is effectively reduced gradually as the period nears its end.
  * If, on the other hand, frozen nodes cannot actually withdraw funds until the freeze period is ended, the freeze penalty has the effect of restricting access to capital. The fact that a withdrawal was attempted suggests that the value of being able to deploy that capital has recently become greater than the potential revenue, which is value of the freezing penalty under normal circumstances. Therefore it is not disproportionate for freezing to prevent withdrawal of funds if the freezing period would overlap the end of the `DRAWDOWN_DELAY` period.
  * Currently, frozen nodes are allowed to make deposits. Under the proposed queue system, funds are deposited at the time a deposit request is entered, but only registered for the purposes of redistribution after the delay `BASE_UPDATE_DELAY`. This only matters if the node participates, which it cannot if frozen. So the choice in this case is irrelevant.
  * If being frozen prevents or delays a node from executing an AoR change at the end of a period, it becomes harder to forecast node movements from queue state (because getting frozen screws that up). But that's the case with freezing anyway. Also, a frozen node cannot participate so its AoR is irrelevant.

  We therefore suggest that freezing be allowed to prevent the withdrawal of funds. All other changes have effect only during participation, which is anyway prevented during freezing.

  Can frozen nodes put in new update requests? I don't see why not.

* *Pausing.* When the Staking contract is paused, `migrateStake` is allowed and `manageStake` is not. Pausing the staking contract has no effect on participation in redistribution. The intention of this construction is to allow stake to move to a new version of the stake registry, so we see no reason to make `migrateStake` calls go via the queue.

### Concurrency

* Different types of action need to be treated differently. If actions are anything other than instantaneous and atomic, we need to deal with concurrency — that is, an update being requested while another is waiting in the queue. 
* *In-order execution.* 
  * Insisting on in-order execution means that actions with short delays (e.g. topping up) can be held up by actions with longer delays (e.g. height reduction). This might not be necessary.
  * On the other hand, allowing out-of-order execution will probably make the analysis way more complicated. It will be harder to make use of the "forecast" function of the queue
* *Request cancellation.* Requires a way to specify which request should be cancelled, and again substantially complicates making use of the information benefits of a public queue. We argue against allowing this.

## Specification

### Parameters

| Name                      | Value  | Description                                            |
| ------------------------- | ------ | ------------------------------------------------------ |
| `EXIT_DELAY`              | `3184` | Minimum delay to impose for height reduction.          |
| `DRAWDOWN_DELAY`          | `796`  | Minimum delay to impose for a drawdown.                |
| `OVERLAY_CHANGE_DELAY`    | `796`  | Minimum delay to impose for change of overlay address. |
| `BASE_UPDATE_DELAY`       | `2`    | Minimum delay to impose for all operations in rounds.  |
| `UPDATE_QUEUE_MAX_LENGTH` | `10`   | Maximum number of pending request items per owner      |

Malicious changes to these variables could have the effect of trapping nodes indefinitely, so we propose that their values be embedded at contract deployment time and not be modifiable by the admin.

### Logic

* Updates that would have been managed by calling `StakeRegistry:manageStake` and `StakeRegistry:withdrawFromStake` are added to a request queue and triggered lazily after a delay instead of executing instantly.
* The queue is FCFS with delays depending on the type of change requested. The FCFS ordering is enforced even when a request with a longer delay is enqueued before one with a shorter delay, causing the latter request to be "held up."

* The following calls may need to check the queue state:

  * `Redistribution:commit()`. Pop and process all updates with `Pending` status in the queue before proceeding with the commit. The call to Pop occurs *after* the check for frozen status, implying that updates are not processed if the node is frozen. (It doesn't actually matter though. Maybe it should be first.)
  * `Redistribution:reveal()`. The counter that tracks reveals for the purposes of updating prices may need an adjustment for nodes currently waiting to leave the neighbourhood.
  * `StakeRegistry:withdrawFromStake()`. Pop updates to determine allowed withdrawal amount. (Currently, this call does not check for frozen status.)

* The Queue state should be maintained in the `StakeRegistry` contract. It implements the following methods:

  * `add(address owner, update)`. Add `update` to the queue of updates for `owner`.

  * `pop(address owner)`. Pop an update from the queue if any are pending, otherwise return an error.

    When `pop` is called, first the queue is checked to see if there are any entries. If not, throw. Otherwise, check the type and block number of the first entry in the queue to see if the minimum delay for that entry has expired.

  * `check_neighbourhood(address owner, bytes prefix)`. **OPTIONAL.** Check if `owner` has any pending updates that would reduce the population of the neighbourhood defined by `prefix`. This needs to be able to read the reported depth. Potentially an expensive operation which must cycle through all enqueued updates, but at least the user must pay for it.

  When an `Update` is added to the queue, the round number of the current round is recorded along with it.

* The `Update` object must record the desired stake balance, height, and overlay address after the update. If the stake balance is reduced to zero, the stake struct may be safely deleted.

* Under certain versions of the queue model, it is possible for the BZZ balance held by the Registry on behalf of an owner to be less than the balance registered for the Redistribution game. That is,

  * In the case of a deposit, BZZ transfer happens on request (?) while registered balance is updated after a delay. (If we allow BZZ transfer to also occur after the delay, the depositor has a free option to cause the deposit to fail by moving his tokens somewhere else.)
  * In the case of a withdrawal, both deregistration and transfer happen after the delay.

  If this happens, then the updates that would register the untracked balances are in a queue and will eventually (after `BASE_UPDATE_DELAY` rounds) be processed.

* In the case of creating a new deposit, a new entry in the stake table may be created, but with zero balance, at the time the request is submitted. The balance is updated when the update is executed.



## Implementation notes

* Following standard practice, the event queue for each owner can be implemented with an address-indexed mapping. (Cf. [OpenZeppelin deque implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/structs/DoubleEndedQueue.sol) and a [Medium article](https://medium.com/@hayeah/diving-into-the-ethereum-vm-the-hidden-costs-of-arrays-28e119f04a9b) warning us about the use of arrays.)

## Security implications

WIP

## Economic implications

The main effect, which is intended, is to slow down interactions with the stake registry, particularly those that could threaten data replication.

* The most serious threat to stability comes from height reduction, which removes a node entirely from the service of a particular neighbourhood. Incentives to reduce height may include:
  * Save on storage costs by reducing commitment.
  * Maintain stake density after a drawdown.
* We expect that the incentives for drawing down stake occur frequently, driven by market conditions and the attractiveness of other opportunities. Currently, the opportunities to draw down stake are limited to when the storage price quote has gone down from when the stake was last "committed," so the negative impact of drawdowns is not particularly concerning. However, we expect that other protocol changes will soon relax these conditions, and the drawdown delay chosen is intended to have some future proofing.
* Changing overlay address does not affect the mean replication rate, but it weakens one neighbourhood while strengthening another. The design of the revenue sharing system implies that the incentives will often be for nodes to move from more populated neighbourhoods to less populated ones, but this need not always be the case. 
  Introducing a modest delay gives the network time to react to such changes, for example by migrating nodes from other neighbourhoods to fill a gap. Discounting exiting nodes from the replication rate counter of the source neighbourhood allows new nodes to enter without triggering downward price pressure.

## Interactions with other proposals

* *Self-custodial/upgradable stake registry.* This change would retire the `migrateStake` endpoint and possibly separate balance and participation metadata management into different contracts.

  When a change to the queue design occurs, metadata changes already in the queue should ideally continue under the old queue logic. If the queue state is part of the Stake Registry contract, there is no way to protect it from arbitrary updates. Thus the queue ought to be part of a new contract accessible by the Redistributor.

  If a self-custodial vault model is used to protect user actions from malicious registry upgrades, a separate Queue contract could facilitate protection of withdrawals by taking over a claim on the funds marked for withdrawal from the Registry, before ultimately returning it to the owner when the withdrawal is ready. It would then be impossible for a Registry upgrade to affect the winding down of the claim.

* *Withdrawable stake.* Withdrawing stake completely needs its own delay, probably the same as for reducing height (or even more severe). Since it doesn't really make sense for exiting to be triggered by a call to `Redistribution:commit()`, exits should have their own triggering method.

  If stake is withdrawable under more general circumstances, we expect that freezing will prevent such withdrawals.