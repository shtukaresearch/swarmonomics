---
title: Stake registry update queue
author: Andrew Macpherson (@awmacpherson)
discussions-to: https://discord.gg/Q6BvSkCv (Swarm Discord)
status: WIP
category: Core
created: 2025-10-10
---

# Stake registry update queue

## Abstract

Introduce a FIFO queue that adds controlled delays to all updates to stake balances and metadata (i.e. height and overlay address).

## Motivation

Currently, the following operations are possible on a stake balance:

* Create/destroy.
* Deposit/withdraw.
* Update height (up/down).
* Update overlay address.

Some of these operations — for example, height reduction — result in a node's exit from or reduced financial commitment to a neighbourhood, negatively affecting the storage service. For the sake of service stability, we propose a method to throttle such operations by means of an update queue which imposes additional delays on service-reducing changes. 

The 2 round thaw currently imposed on stakers after any change to participation metadata is absorbed into the logic of this queue. Instead of being blocked from participation, possibly leading to service disruption, stakers can continue to play using their existing stake metadata during the 2 round delay.

Requests to update registered information (committed stake, height, and overlay address) are placed on a FIFO queue, maintained by a new UpdateQueue subsystem, and executed lazily on calls to getter methods in the Stake Registry contract. An update is not processed unless a certain number of complete rounds has elapsed since it was placed on the queue. The number of rounds depends on the nature of the update; updates that allow stake balances to be reduced or nodes to remove neighbourhoods from their area of responsibility are subjected to longer delays.

## Specification

### Architecture

The proposal calls for the deployment of a new UpdateQueue contract that manages a queue of calls to setter methods in the Stake Registry. The Stake Registry maintains a reference to the UpdateQueue contract so that it can push requests to and pop from the queue. No other contracts or entities need to access the UpdateQueue contract directly. 

### Parameters

| Name                      | Value  | Description                                                  |
| ------------------------- | ------ | ------------------------------------------------------------ |
| `EXIT_DELAY`              | `3184` | Minimum delay in rounds to impose for height reduction       |
| `OVERLAY_CHANGE_DELAY`    | `796`  | Minimum delay in rounds to impose for change of overlay address. |
| `BASE_UPDATE_DELAY`       | `2`    | Minimum delay in rounds to impose for all operations.        |
| `UPDATE_QUEUE_MAX_LENGTH` | `10`   | Maximum number of pending request items per owner.           |

Malicious changes to these variables could have the effect of trapping nodes indefinitely, so we propose that their values be embedded into the UpdateQueue contract at deployment time and not be modifiable by the admin.

### StakeRegistry

* Updates that would have been managed by calling `StakeRegistry:manageStake` are added to a request queue and triggered lazily after a delay, which is determined by the queue subsystem, instead of executing instantly. The type of delay to impose depends on the update and is decided at the time of adding the update to the queue.

  The delay to impose is decided as follows:

  1. If `height` is reduced, apply `ExitDelay`.
  2. Otherwise, if overlay address is changed, apply `OverlayChangeDelay`.
  3. Otherwise apply `BaseDelay`.

  A new access-controlled call `StakeRegistry:_manageStake` that can only be called by the UpdateQueue contract must be implemented to actually apply the updates.

* Calls to `StakeRegistry:migrateStake` clear the queue and withdraw immediately.

* The logic of `withdrawFromStake` must define `_surplusStake` using the look-ahead value of `committedStake` rather than the active value.

* `lastUpdatedBlockNumber` is now only used for freezing.

* The `Redistribution.commit()` method wants to pop all valid updates from the queue before getting the values of the view functions `overlayOfAddress()`, `nodeEffectiveStake()`, `lastUpdatedBlockNumberOfAddress()`, and `heightOfAddress()`. Should it do this explicitly, or should it be baked into the definition of those functions (which breaks the `view` property)? 

  I think we need two sets of endpoints: `view` endpoints that apply pending updates in memory but do not modify state, and endpoints with side-effects that apply the updates to state before returning.

#### Tests

* The Stake Registry cannot report stale values. All `view` endpoints as well as `updateAndGet*` endpoints
* Calls to `manageStake` should be enqueued in order and with correct delays.
  * A "trivial" update with `_setNonce` and `height` the same as before and `_addAmount = 0` receives the Base Delay. Trivial updates may still result in a change to `committedStake`. More generally, any update which leaves `_setNonce` unchanged and does not decrease `height` receives Base Delay.
  * Any update that decreases `height` receives the Exit Delay, regardless of what other changes it makes.
  * An update that changes `_setNonce` and either leaves `height` the same or increases it receives the Overlay Change Delay.
  * FIFO structure: if a `height` decrease is enqueued, then an update with a short delay is enqueued, the second update is not applied until after the full `EXIT_DELAY`.
* Call to `migrateStake` correctly processes enqueued deposit liabilities and withdraws all deposited tokens (when paused).
* Call to `withdrawFromStake` takes enqueued stake commitment into account when computing stake surplus. If there is some surplus, enqueuing another update makes that surplus instantly committed and inaccessible to `withdrawFromStake`.

#### Sample implementation

```solidity
enum delay_t { BaseDelay, ExitDelay, OverlayChangeDelay }

contract StakeRegistry {
    function manageStake(bytes32 _setNonce, uint256 _addAmount, uint8 _height) external whenNotPaused {
        // As in v0.9.3 except with the following section removed:
        /*  
            stakes[msg.sender] = Stake({
                overlay: _newOverlay,
                committedStake: updatedCommittedStake,
                potentialStake: updatedPotentialStake,
                lastUpdatedBlockNumber: block.number,
                height: _height
            });
        */ 
        // and the following added:
        
        // Select delay type based on nature of update
        delay_t delay
        if (_height < stakes[msg.sender].height)
            delay = ExitDelay;
        else if (_newOverlay != _previousOverlay)
            delay = OverlayChangeDelay;
        else
            delay = BaseDelay;
        
        // Encode call and push to queue with configured delay
        bytes request = abi.encodeCall(
            setStake, (msg.sender, _newOverlay, updatedCommittedStake, updatedPotentialStake, block.number, _height)
        );
        UpdateQueue.push(msg.sender, request, delay);
    }
     
    // private method to be called directly by requests popped from the queue
    function setStake internal (
        address owner, 
        bytes32 overlay, 
        uint committedStake, 
        uint potentialStake, 
        uint blockNumber,
        uint8 height
    ) {
        stakes[owner] = Stake({
            overlay: overlay,
            committedStake: committedStake,
            potentialStake: potentialStake,
            lastUpdatedBlockNumber: blockNumber,
            height: height
        });
    }
    
    // Getter methods that apply valid updates in state before returning
    function updateAndGetOverlay(address owner) external returns bytes32;
    function updateAndGetCommittedStake(address owner) external returns uint256;
    function updateAndGetPotentialStake(address owner) external returns uint256;
    function updateAndGetHeight(address owner) external returns uint8;
    
    // Pure variants of the above that apply valid updates in memory before returning but don't modify state
    function getOverlay(address owner) external pure returns bytes32;
    function getCommittedStake(address owner) external pure returns uint256;
    function getPotentialStake(address owner) external pure returns uint256;
    function getHeight(address owner) external pure returns uint8;
    
    // Getter methods that apply all enqueued updates (without waiting) in memory before returning.
    function lookAheadOverlay(address owner) external view returns bytes32;
    // Required by lookAheadInProximity method used by Redistribution:reveal().
    
    function lookAheadCommittedStake(address owner) external view returns uint256;
    // Required by withdrawFromStake.
    
    function lookAheadPotentialStake(address owner) external view returns uint256;
    // Could be used by migrateStake.
    
    function lookAheadHeight(address owner) external view returns uint8;
    // Required by lookAheadInProximity method used by Redistribution:reveal().
}
```

#### Redistribution

* The following calls may need to check the queue state:

  * `Redistribution:commit()`. Pop and process all updates with `Pending` status in the queue before proceeding with the commit. The call to Pop occurs *after* the check for frozen status, implying that updates are not processed if the node is frozen. (This matters if the updates also set `lastUpdatedBlockNumber`.)
  * `Redistribution:reveal()`. The counter that tracks reveals for the purposes of updating prices may need an adjustment for nodes currently waiting to leave the neighbourhood. **TODO** Specify how this works.
* `Redistribution:commit()` currently checks the `lastUpdatedBlockNumber` to see if a node can participate. This is used in freezing as well as the post-update thaw. 

**Tests.**

* `commit()` does not access stale state. Pending updates are always applied before values are used.
* If less than 2 rounds have elapsed since any update was enqueued, `commit()` sees the same metadata as before. Therefore the same `obfuscatedHash` should be usable.

#### UpdateQueue

When an update is added to the queue, the round number of the current round is recorded along with it. The `Update` object records the call into the Staking contract that performs the metadata update.

```solidity
struct Update {
  uint validAfterRound;
  bytes callData;
}
```

The queue is FIFO with delays of various lengths classified by an enum:

* `ExitDelay` 
* `OverlayChangeDelay`
* `BaseDelay`

The delay can be thought of as a "not valid before" timer. An update is not necessarily applicable immediately after this delay expires: due to FIFO ordering, it could be held up by another request higher up in the queue with a longer delay.

The queue must provide look-ahead overlay address, height, and committed stake balance. Due to FIFO ordering, this can be computed simply by applying the most recently enqueued update.

```solidity
struct UpdateQueue {
    Queue<Update> updates;
    bytes32 lookAheadOverlay;
    uint256 lookAheadCommittedStake;
    uint8 lookAheadHeight;
}

mapping(address => UpdateQueue) public updateQueue;
```

#### Interface

````solidity
interface IUpdateQueue {
    function push(address owner, bytes encodedCall, delay_t delay) external;
    // Add update `encodedCall` to the queue of updates for `owner` with validity 
    // in rounds starting after a delay of type `delay`.
    
    function pop(address owner) external returns bytes;
    // Pop an encoded function call from the queue if any valid calls are pending
    // otherwise throw an error
    
    function clear(address owner) external whenPaused returns uint256;
    // Delete queue data associated to owner. Can only be called via migrateStake.
}
````

## Rationale

* *One queue.* All types of updates for all stake owners are considered to be part of one queue. While some queue designs may allow for handling different owners or different update types in isolation, others — such as a global churn rate limiter — require tracking global state. To future proof the queue interface against possible changes to queue design, other components of the system must treat the entire network-wide queue as a single black box.

* *Separate UpdateQueue contract.* We propose the update queue be maintained in a separate contract from the Stake Registry for the sake of maximising modularity and potentially isolating parts of deployments from unrelated upgrades.

  For the sake of gas efficiency, the UpdateQueue contract could be inlined into the StakeRegistry. However, we find this to be a premature optimisation that gives up modularity for the sake of gas fees that are basically insignificant (millionths of a dollar) in practice.

* *2 round thaw.* The 2 round thaw currently implemented (but not fully documented) in the `commit()` method of the Redistribution contract is absorbed into this queue. The delay length is preserved as the `BASE_UPDATE_DELAY` parameter. However, unlike in the old model, participation is still allowed during the thaw period — but under the old stake position.

* *Event emission.* Requesting updates should emit an event, because NOs will want to track these for their strategies. We don't need to emit an event when the update is actually applied. In any case, the time that the update is processed is not really economically significant; it just gets done whenever that node is next able to participate.

* *Per-neighbourhood delay scaling.* It may make sense to adjust the delay of changes depending on the before and after population of each neighbourhood affected by the change. The core example is to reduce delay for nodes leaving a neighbourhood with large population (and in the case of overlay change, entering one with small population). This would require the queue system to be able to estimate replication depth and enlarges the design space considerably, so we omit it from the present proposal.

* *Maximum queue length.* Although unlikely to be an issue in practice, in principle an update queue could grow so long that it cannot be emptied in a single block. Therefore, there shold be a maximum number of updates that can be held in the queue for each owner. It probably won't cause a big problem if the number is quite small, e.g. 10.

  An alternative approach would be to internally merge operations using an internal representation closed under composition. While we can imagine ways to do this for the set of operations the queue is currently expected to process, it would complicate the process of adding any new types of operation to the queue or changing the queue algorithm. A simple maximum queue length is easy to implement, universal, and unlikely to raise any serious objections.
  
* *Staker commitments.* Staker commitments, i.e. transfers to the stake registry and latest-price updates to committed stake, must be binding for the staker at the time the update is requested. The queue subsystem must be able to report up-to-date commitments. The effect of the new commitment (i.e. the new `committedStake` balance can be used in Redistribution) does not apply until after the delay.

* *Liability tracking.* The proposed changes mean that the `potentialStake` recorded under a given `owner` in the Stake Registry does not always equal the total amount of BZZ deposited by that owner (net of surplus withdrawals). Rather, the records of liabilities of the Stake Registry to a given owner are split between the Registry itself and the Update Queue. Since these records control what can be withdrawn by calling the `withdrawFromStake` and `migrateStake` methods, these processes must either block on not-yet-active updates, or fast track and apply them.

* *Manual queue triggering.* Manual popping of updates from the queue can be allowed, but since the updated metadata is only used during participation, there is not likely to be much incentive to do that. (This changes if reducing committed stake is allowed.)

* *Lookahead.* In the present design, the following methods make use of a lookahead:

  * `migrateStake`. Since this is called when the Stake Registry is paused, withdrawable amounts should be accelerated (?). The new Stake Registry may reference the same queue. Two Stake Registries should not simultaneously be able to mutate the queue state.
  * `withdrawFromStake`. Because surplus stake is defined in terms of a "committed stake" quantity that is locked in at the time an update is enqueued, this method needs to look ahead to see how much has been committed. Under a generally withdrawable stake system that eliminates dependence on the storage price, this wouldn't be needed.
  * `reveal`. Because we ask that the reveal counter look ahead at nodes that are committed to exit for the sake of adjusting prices, this method needs to look ahead to `overlay` and `height`.

  The FIFO design considerably simplifies the calculation of lookahead compared to other designs. 

* *Update encoding.* There are two basic approaches to recording the data of an "update" in the UpdateQueue:

  1. Record the new values to be applied in a struct.
  2. Directly encode the calldata of the call that will be made.

  Option (2) is future-proof in the sense that the same encoding will make sense if new types of update are introduced. OTOH it is less suitable for introspection than (1). We argue that the Queue contract itself should not be doing any introspection — it simply keeps track of *when* each update should be applied, and it is the caller's responsibility to hand it enough data to make that call. From this perspective, the opacity of an encoded call is also an advantage.

### Effect of pending status on other components

* *Price oracle.* For the purposes of adjusting storage prices, the reveal counter should discount nodes currently waiting to exit the neighbourhood. Fully discounting it allows another node to enter and sync before the population shrinks without triggering negative price pressure. If no new node is ready to enter, this allows the system to begin adjusting prices from as soon as the potential supply shrinkage is known.

  On the other hand, if a queue discipline with variable wait times is used — for example, one with a global maximum on the number of changes per round — then this approach could cause prices to be pushed up unnecessarily just because of congestion on the queue.

  It is natural to ask whether a node waiting to *enter* a different neighbourhood, for example by an overlay change, be considered as part of that neighbourhood for the sake of price adjustments. The current design means that we can only do this if nodes participate in the new neighbourhood while waiting in the queue, which would mean they need to be treated as having two overlay addresses for a period. Since reacting to neighbourhood underpopulation is more important than reacting to overpopulation, it may be OK to skip this one.

  This discounting could also be on a time-based curve, but that seems like it might be hard to implement.

* *Reward sharing.* For most of the benefits of an exit queue to work, nodes must be incentivised to continue operating while they are in the queue. Hence, they must be able to continue participating in reward sharing (and penalties) using their previous participation metadata while waiting. Accordingly, they must participate in all the activities that qualify them for reward sharing, i.e. reserve consensus and storage and density proofs.

* *Freezing.* If a node gets frozen while waiting to withdraw funds, what happens?

  * If withdrawal is allowed even if the stake is frozen at the end of the wait period, the penalty implied by freezing is effectively reduced gradually as the period nears its end.
  * If, on the other hand, frozen nodes cannot actually withdraw funds until the freeze period is ended, the freeze penalty has the effect of restricting access to capital. The fact that a withdrawal was attempted suggests that the value of being able to deploy that capital has recently become greater than the potential revenue, which is value of the freezing penalty under normal circumstances. Therefore it is not disproportionate for freezing to prevent withdrawal of funds if the freezing period would overlap the end of the `DRAWDOWN_DELAY` period.
  * Currently, frozen nodes are allowed to make deposits. Under the proposed queue system, funds are deposited at the time a deposit request is entered, but only registered for the purposes of redistribution after the delay `BASE_UPDATE_DELAY`. This only matters if the node participates, which it cannot if frozen. So the choice in this case is irrelevant.
  * If being frozen prevents or delays a node from executing an AoR change at the end of a period, it becomes harder to forecast node movements from queue state (because getting frozen screws that up). But that's the case with freezing anyway. Also, a frozen node cannot participate so its AoR is irrelevant.

  We therefore suggest that freezing be allowed to prevent the withdrawal of funds. All other changes have effect only during participation, which is anyway prevented during freezing.

  Can frozen nodes put in new update requests? I don't see why not.

* *Pausing.* When the Staking contract is paused, `migrateStake` is allowed and `manageStake` is not. Pausing the staking contract has no effect on participation in redistribution. The intention of this construction is to allow stake to move to a new version of the stake registry, so we see no reason to make `migrateStake` calls go via the queue. Instead, they should immediately clear and delete the queue, making sure to process all updates to liabilities in the form of `potentialStake`, and process the withdrawal.

### Concurrency

* If actions are anything other than instantaneous and atomic, we need to deal with concurrency — that is, an update being requested while another is waiting in the queue. 
* Different types of action ought to be treated differently, whence multiple delay types. 
* *In-order execution.* 
  * Insisting on in-order execution means that actions with short delays (e.g. topping up) can be held up by actions with longer delays (e.g. height reduction). This might not be necessary.
  * On the other hand, allowing out-of-order execution will probably make the analysis way more complicated. It will be harder to make use of the "forecast" function of the queue
* *Request cancellation.* Requires a way to specify which request should be cancelled, and again substantially complicates making use of the information benefits of a public queue. It is simpler and more elegant not to allow cancellations.

## Implementation notes

* Following standard practice, the event queue for each owner can be implemented with an address-indexed mapping. (Cf. [OpenZeppelin deque implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/structs/DoubleEndedQueue.sol) and a [Medium article](https://medium.com/@hayeah/diving-into-the-ethereum-vm-the-hidden-costs-of-arrays-28e119f04a9b) warning us about the use of arrays.)

## Security implications

* The update queue subsystem takes ownership, in the form of `BASE_UPDATE_DELAY`, of the 2 round metadata update delay currently found in the initial validation checks of the `Redistribution:commit()` call. A top-up or deposit delay of at least until the end of the current round is required to prevent shadow stake attacks. No immediate changes to security model for shadow stake or penalty evasion are implied by the current proposal, but care needs to be taken in future to preserve the `BASE_UPDATE_DELAY` minimum.
* In the proposed access control model, anyone may trigger processing of valid updates from anyone else's queue. Since updates cannot be cancelled and would be processed anyway before the state can be used in redistribution, this is harmless.

## Economic implications

The main effect, which is intended, is to slow down interactions with the stake registry, particularly those that could threaten data replication.

* The most serious threat to stability comes from height reduction, which removes a node entirely from the service of a particular neighbourhood. Incentives to reduce height may include:
  * Save on storage costs by reducing commitment.
  * Maintain stake density after a drawdown.
* We expect that the incentives for drawing down stake occur frequently, driven by market conditions and the attractiveness of other opportunities. Currently, the opportunities to withdraw stake are limited to when the storage price quote has gone down from when the stake was last "committed." Since only "uncommitted" stake can be withdrawn, withdrawing it has no immediate impact on the incentive to continue providing good service on the node, so no delay is needed.
* Changing overlay address does not affect the mean replication rate, but it weakens one neighbourhood while strengthening another. The design of the revenue sharing system implies that the incentives will often be for nodes to move from more populated neighbourhoods to less populated ones, but this need not always be the case. 
  Introducing a modest delay gives the network time to react to such changes, for example by migrating nodes from other neighbourhoods to fill a gap. Discounting exiting nodes from the replication rate counter of the source neighbourhood allows new nodes to enter without triggering downward price pressure.

## Interactions with other proposals

* *Self-custodial/upgradable stake registry.* This change would retire the `migrateStake` endpoint and possibly separate balance and participation metadata management into different contracts.

  When a change to the queue design occurs, metadata updates already waiting in the queue should ideally continue be processed under the old queue logic. If the queue state is part of the Stake Registry contract, there is no way to protect it from arbitrary updates. Thus the queue ought to be part of a new contract accessible by the Redistributor.

  If a self-custodial vault model is used to protect user actions from malicious registry upgrades, a separate Queue contract could facilitate protection of withdrawals by taking over a claim on the funds marked for withdrawal from the Registry, before ultimately returning it to the owner when the withdrawal is ready. It would then be impossible for a Registry upgrade to affect the winding down of the claim.

* *Withdrawable stake.* Withdrawing stake completely needs its own delay, at least as severe as for reducing height. Since it doesn't really make sense for exiting to be triggered by a call to `Redistribution:commit()`, there should be a separate endpoint to manually trigger exits.

  If stake is withdrawable under more general circumstances, we expect that freezing will prevent such withdrawals.
  
* *Automatic address balancing.* Current versions of automatic neighbourhood assignment call for a delayed commit/execute scheme to be allocated a neighbourhood after staking. The present update queue proposal provides a subsystem to implement this delay.